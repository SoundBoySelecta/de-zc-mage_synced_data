{"block_file": {"/home/src/default_repo/data_exporters/export_gcs_partitioned_gtd_2020_final_quarter.py:data_exporter:python:home/src/default repo/data exporters/export gcs partitioned gtd 2020 final quarter": {"content": "import pyarrow as pa\nimport pyarrow.parquet as pq\nimport os\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\nos.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/src/default_repo/proven-catcher-mage-demo.json'\nbucket_name = 'proven-catcher-411305-mago-demo'\nproject_id = 'proven-catcher-411305'\ntable_name = 'gtd_2020_final_qtr_partition_by_date'\nroot_path = f\"{bucket_name}/{table_name}\"\n@data_exporter\ndef export_data(data, *args, **kwargs):\n    \"\"\"\n    Exports data to some source.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Output (optional):\n        Optionally return any object and it'll be logged and\n        displayed when inspecting the block run.\n    \"\"\"\n    # Specify your data exporting logic here\n    table = pa.Table.from_pandas(data)\n    gcs = pa.fs.GcsFileSystem()\n    pq.write_to_dataset(\n        table,\n        root_path = root_path,\n        partition_cols = ['lpep_pickup_date'],\n        filesystem = gcs\n\n    )\n    \n\n\n", "file_path": "/home/src/default_repo/data_exporters/export_gcs_partitioned_gtd_2020_final_quarter.py", "language": "python", "type": "data_exporter", "uuid": "export_gcs_partitioned_gtd_2020_final_quarter"}, "/home/src/default_repo/data_loaders/load_gtd_2020_final_qtr.py:data_loader:python:home/src/default repo/data loaders/load gtd 2020 final qtr": {"content": "import pandas as pd\n# import parquet-tools\n\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data(*args, **kwargs):\n    \"\"\"\n    Template code for loading data from any source.\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    periods = []\n    for i in range(1, 13):\n        if len(str(i)) == 1:\n            periods.append(f'2022-{str(i).zfill(2)}')\n        else:\n            periods.append(f'2022-{i}')\n    for period in periods:\n        url = f'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_{period}.parquet'\n        print(url)\n    url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2022-01.parquet'\n    df = pd.read_parquet(url)\n    print(df.shape)\n#     #Create an empty list to store all df\n#     dfs = {}\n#     for month in months:\n#         url = f'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_{month}.csv.gz'\n        \n#         df_name = f'gtd_{month}'\n#         dfs[df_name] =  pd.read_csv(url, compression='gzip', dtype=taxi_dtypes, parse_dates=parse_dates)\n\n#    # Assert all 3 dfs align in length of columns\n#     assert len(set([df.shape[1] for df in dfs.values()])) == 1, \"Column lengths in each dataframes are not equal\"\n   \n#     #Concatenate all dataframes\n#     gtd_2020_final_qtr = pd.concat(list(dfs.values()))\n\n\n\n    \n    # return gtd_2020_final_qtr\n\n  \n# @test\n# def test_output(output, *args) -> None:\n#     \"\"\"\n#     Template code for testing the output of the block.\n#     \"\"\"\n#     assert output is not None, 'The output is undefined'\n", "file_path": "/home/src/default_repo/data_loaders/load_gtd_2020_final_qtr.py", "language": "python", "type": "data_loader", "uuid": "load_gtd_2020_final_qtr"}}}